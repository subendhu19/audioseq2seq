{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd, gluon, autograd\n",
    "\n",
    "import gluonnlp as nlp\n",
    "import pickle\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "mx.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pickle.load(open('../data/dev_processed.p', 'rb'))\n",
    "test_dataset = pickle.load(open('../data/dev_processed.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {'<pad>': [0, 1], '<unk>': [1, 1], '<BOS>': [2, 1], '<EOS>': [3, 1]}\n",
    "for item in train_dataset + test_dataset:\n",
    "    words = item[2].split(' ')\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            vocabulary[word][1] += 1\n",
    "        else:\n",
    "            vocabulary[word] = [len(vocabulary), 1]\n",
    "\n",
    "vocabulary_inv = {}\n",
    "for key in vocabulary:\n",
    "    vocabulary_inv[vocabulary[key][0]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    name, audio, words = x\n",
    "    split_words = ['<BOS>'] + words.split(' ') + ['<EOS>']\n",
    "    return audio, np.array([vocabulary[word][0] for word in split_words]), float(len(audio)), float(len(split_words))\n",
    "\n",
    "def get_length(x):\n",
    "    return float(len(x[1]))\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    start = time.time()\n",
    "    with mp.Pool() as pool:\n",
    "        dataset = gluon.data.SimpleDataset(pool.map(preprocess, dataset))\n",
    "        lengths = gluon.data.SimpleDataset(pool.map(get_length, dataset))\n",
    "    end = time.time()\n",
    "    print('Done! Processing Time={:.2f}s, #Samples={}'.format(end - start, len(dataset)))\n",
    "    return dataset, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Processing Time=2.56s, #Samples=2703\n",
      "Done! Processing Time=2.16s, #Samples=2703\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_data_lengths = preprocess_dataset(train_dataset)\n",
    "test_dataset, test_data_lengths = preprocess_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=2703, batch_num=82\n",
      "  key=[13, 22, 31, 40, 49, 58, 67, 76, 85, 94]\n",
      "  cnt=[837, 805, 531, 282, 120, 70, 30, 15, 8, 5]\n",
      "  batch_size=[46, 32, 32, 32, 32, 32, 32, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "learning_rate, batch_size = 0.005, 32\n",
    "bucket_num, bucket_ratio = 10, 0.2\n",
    "grad_clip = None\n",
    "log_interval = 5\n",
    "\n",
    "def get_dataloader():\n",
    "    batchify_fn = nlp.data.batchify.Tuple(\n",
    "        nlp.data.batchify.Pad(dtype='float32'),\n",
    "        nlp.data.batchify.Pad(dtype='float32'),\n",
    "        nlp.data.batchify.Stack(dtype='float32'),\n",
    "        nlp.data.batchify.Stack(dtype='float32'))\n",
    "    batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
    "        train_data_lengths,\n",
    "        batch_size=batch_size,\n",
    "        num_buckets=bucket_num,\n",
    "        ratio=bucket_ratio,\n",
    "        shuffle=True)\n",
    "    print(batch_sampler.stats())\n",
    "\n",
    "    train_dataloader = gluon.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        batchify_fn=batchify_fn)\n",
    "    test_dataloader = gluon.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        batchify_fn=batchify_fn)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "train_dataloader, test_dataloader = get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from io import open\n",
    "from mxnet import gluon, autograd\n",
    "from mxnet.gluon import nn, rnn, Block\n",
    "from mxnet import ndarray as F\n",
    "from gluonnlp.model.transformer import TransformerEncoder\n",
    "from gluonnlp.model.transformer import TransformerDecoder\n",
    "\n",
    "class SubSampler(gluon.HybridBlock):\n",
    "    def __init__(self, size=3, prefix=None, params=None):\n",
    "        super(SubSampler, self).__init__(prefix=prefix, params=params)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, data, valid_length):\n",
    "        masked_encoded = F.SequenceMask(data,\n",
    "                                        sequence_length=valid_length,\n",
    "                                        use_sequence_length=True)\n",
    "        subsampled = F.Pooling(masked_encoded.swapaxes(0,2), kernel=(self.size), pool_type='max', stride=self.size).swapaxes(0,2)\n",
    "        sub_valid_length = mx.nd.ceil(valid_length / self.size)\n",
    "        return subsampled, sub_valid_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioEncoder(Block):\n",
    "    def __init__(self, input_size, hidden_size, sub_sample_size=3):\n",
    "        super(AudioEncoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sub_sample_size = sub_sample_size\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.proj = nn.Dense(hidden_size, flatten=False)\n",
    "            self.t1 = TransformerEncoder(units=self.hidden_size, num_layers=1, hidden_size=16, max_length=50, num_heads=1)\n",
    "            self.subsampler = SubSampler(self.sub_sample_size)\n",
    "            self.t2 = TransformerEncoder(units=self.hidden_size, num_layers=1, hidden_size=16, max_length=50, num_heads=1)\n",
    "\n",
    "    def forward(self, input, lengths):\n",
    "        input = self.proj(input)\n",
    "        output, _ = self.t1(input, None, lengths)\n",
    "        output = output.swapaxes(0,1)\n",
    "        subsampled, sub_lengths = self.subsampler(output, lengths)\n",
    "        subsampled = subsampled.swapaxes(0,1)\n",
    "        output, _ = self.t2(subsampled, None, sub_lengths)\n",
    "        return output, sub_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioWordDecoder(Block):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(AudioWordDecoder, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "            self.t = TransformerDecoder(units=self.hidden_size, num_layers=1, hidden_size=16, max_length=50, num_heads=1)\n",
    "            self.out = nn.Dense(output_size, in_units=self.hidden_size, flatten=False)\n",
    "\n",
    "    def forward(self, input, enc_outs, enc_valid_lengths, dec_valid_lengths):\n",
    "        output = self.embedding(input)\n",
    "        dec_states = self.t.init_state_from_encoder(enc_outs, enc_valid_lengths)\n",
    "        output, _, _ = self.t.decode_seq(output, dec_states, dec_valid_lengths)\n",
    "        output = self.out(output)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(Block):\n",
    "    def __init__(self, input_size, output_size, enc_hidden_size, dec_hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        with self.name_scope():\n",
    "            self.encoder = AudioEncoder(input_size=input_size, hidden_size=enc_hidden_size)\n",
    "            self.decoder = AudioWordDecoder(hidden_size=dec_hidden_size, output_size=output_size)\n",
    "    \n",
    "    def forward(self, audio, alengths, words, wlengths):\n",
    "        encoder_outputs, encoder_out_lengths = self.encoder(audio, alengths)\n",
    "        decoder_outputs = self.decoder(words, encoder_outputs, encoder_out_lengths, wlengths)\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.loss import Loss as Loss\n",
    "\n",
    "class SoftmaxSequenceCrossEntropyLoss(Loss):\n",
    "    def __init__(self, axis=-1, sparse_label=True, from_logits=False, weight=None,\n",
    "                 batch_axis=0, **kwargs):\n",
    "        super(SoftmaxSequenceCrossEntropyLoss, self).__init__(\n",
    "            weight, batch_axis, **kwargs)\n",
    "        self._axis = axis\n",
    "        self._sparse_label = sparse_label\n",
    "        self._from_logits = from_logits\n",
    "    \n",
    "    def hybrid_forward(self, F, pred, label, valid_length):\n",
    "        if not self._from_logits:\n",
    "            pred = F.log_softmax(pred, self._axis)\n",
    "        loss = mx.nd.squeeze(-F.pick(pred, label, axis=self._axis, keepdims=True), axis=2)\n",
    "        loss = F.SequenceMask(loss.swapaxes(0,1), \n",
    "                              sequence_length=valid_length,\n",
    "                              use_sequence_length=True).swapaxes(0,1)\n",
    "        return F.mean(loss, axis=self._batch_axis, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Seq2Seq(input_size=13, output_size=8337, enc_hidden_size=16, dec_hidden_size=16)\n",
    "net.initialize(mx.init.Xavier(), ctx=context)\n",
    "\n",
    "class beamDecoder(object):\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "    def __call__(self, outputs, dec_states):\n",
    "        outputs = self._model.decoder.embedding(outputs)\n",
    "        outputs, new_states, _ = self._model.decoder.t(outputs, dec_states)\n",
    "        return self._model.decoder.out(outputs), new_states\n",
    "\n",
    "scorer = nlp.model.BeamSearchScorer(alpha=0, K=5, from_logits=False)\n",
    "eos_id = vocabulary['<EOS>'][0]\n",
    "beam_sampler = nlp.model.BeamSearchSampler(beam_size=5,\n",
    "                                           decoder=beamDecoder(net),\n",
    "                                           eos_id=eos_id,\n",
    "                                           scorer=scorer,\n",
    "                                           max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_accuracy(s1, l1, s2, l2):\n",
    "    s1 = mx.nd.cast(s1, dtype='int32')\n",
    "    l1 = mx.nd.cast(l1, dtype='int32')\n",
    "    s2 = mx.nd.cast(s2, dtype='int32')\n",
    "    l2 = mx.nd.cast(l2, dtype='int32')\n",
    "    padding = mx.nd.zeros((s1.shape[0], abs(s1.shape[1] - s2.shape[1])), dtype=s2.dtype)\n",
    "    if s1.shape[1] > s2.shape[1]:\n",
    "        s2 = mx.nd.concat(s2, padding, dim=1)\n",
    "    else:\n",
    "        s1 = mx.nd.concat(s1, padding, dim=1) \n",
    "    accs = F.SequenceMask((s1 == s2).swapaxes(0,1), \n",
    "                          sequence_length=mx.nd.minimum(l1, l2), \n",
    "                          use_sequence_length=True)\n",
    "    return (mx.nd.cast(accs.sum(), dtype='float32')/mx.nd.cast(l1.sum(), dtype='float32')).asnumpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, context):\n",
    "    for i, (audio, words, alength, wlength) in enumerate(test_dataloader):\n",
    "        encoder_outputs, encoder_out_lengths = net.encoder(audio.as_in_context(context), alength)\n",
    "        outputs = mx.nd.array([2] * words.shape[0])\n",
    "        decoder_states = net.decoder.t.init_state_from_encoder(encoder_outputs, encoder_out_lengths)\n",
    "        samples, scores, valid_lengths = beam_sampler(outputs, decoder_states)\n",
    "        best_samples = samples[:,0,1:-1]\n",
    "        best_vlens = valid_lengths[:,0]\n",
    "        return get_sequence_accuracy(words, wlength, best_samples, best_vlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, context, epochs):\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'ftml',\n",
    "                            {'learning_rate': learning_rate})\n",
    "    loss = SoftmaxSequenceCrossEntropyLoss()\n",
    "\n",
    "    parameters = net.collect_params().values()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        epoch_L = 0.0\n",
    "        epoch_sent_num = 0\n",
    "        epoch_wc = 0\n",
    "\n",
    "        start_log_interval_time = time.time()\n",
    "        log_interval_wc = 0\n",
    "        log_interval_sent_num = 0\n",
    "        log_interval_L = 0.0\n",
    "\n",
    "        for i, (audio, words, alength, wlength) in enumerate(train_dataloader):\n",
    "            wc = alength.sum().asscalar()\n",
    "            log_interval_wc += wc\n",
    "            epoch_wc += wc\n",
    "            log_interval_sent_num += audio.shape[1]\n",
    "            epoch_sent_num += audio.shape[1]\n",
    "            with autograd.record():\n",
    "                decoder_outputs = net(audio.as_in_context(context), alength, words.as_in_context(context), wlength)\n",
    "                L = loss(decoder_outputs, words.as_in_context(context), wlength).sum()\n",
    "            L.backward()\n",
    "            \n",
    "            if grad_clip:\n",
    "                gluon.utils.clip_global_norm(\n",
    "                    [p.grad(context) for p in parameters],\n",
    "                    grad_clip)\n",
    "            \n",
    "            trainer.step(1)\n",
    "            log_interval_L += L.asscalar()\n",
    "            epoch_L += L.asscalar()\n",
    "            if (i + 1) % log_interval == 0:\n",
    "                print(\n",
    "                    '[Epoch {} Batch {}/{}] elapsed {:.2f} s, '\n",
    "                    'avg loss {:.6f}, throughput {:.2f}K fps'.format(\n",
    "                        epoch, i + 1, len(train_dataloader),\n",
    "                        time.time() - start_log_interval_time,\n",
    "                        log_interval_L / log_interval_sent_num, log_interval_wc\n",
    "                        / 1000 / (time.time() - start_log_interval_time)))\n",
    "                start_log_interval_time = time.time()\n",
    "                log_interval_wc = 0\n",
    "                log_interval_sent_num = 0\n",
    "                log_interval_L = 0\n",
    "        \n",
    "        end_epoch_time = time.time()\n",
    "        test_acc = evaluate(net, context)\n",
    "        print('[Epoch {}] train avg loss {:.6f}, test acc {:.2f}, '\n",
    "              'throughput {:.2f}K fps'.format(\n",
    "              epoch, epoch_L / epoch_sent_num, test_acc,\n",
    "              epoch_wc / 1000 / (end_epoch_time - start_epoch_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, context, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(sampler, inputs, begin_states, num_print_outcomes):\n",
    "    samples, scores, valid_lengths = sampler(inputs, begin_states)\n",
    "    print('Generation Result:')\n",
    "    \n",
    "    for sample_id in range(samples.shape[0]):\n",
    "        sample = samples[sample_id].asnumpy()\n",
    "        score = scores[sample_id].asnumpy()\n",
    "        valid_length = valid_lengths[sample_id].asnumpy()\n",
    "\n",
    "        for i in range(num_print_outcomes):\n",
    "            sentence = []\n",
    "            for ele in sample[i][:valid_length[i]]:\n",
    "                sentence.append(vocabulary_inv[ele])\n",
    "            print([' '.join(sentence), score[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Result:\n",
      "['<BOS> A IN IN IN A A A IN IN IN IN IN IN IN IN IN A A A A <EOS>', -165.40189]\n",
      "['<BOS> IN IN IN IN THE ALL ALL IN IN IN IN ALL ALL ALL IN IN A A A A <EOS>', -166.51385]\n",
      "['<BOS> THE IN IN IN IN IN IN IN IN IN IN IN IN IN IN IN IN THE THE THE <EOS>', -163.97751]\n",
      "['<BOS> THE THE THE THE THE THE THE THE THE THE THE THE THE THE THE THE THE THE THE THE <EOS>', -164.52054]\n",
      "['<BOS> WAS WAS WAS WAS WAS WAS SO SO SO SO SO SO SO SO SO SO WAS WAS WAS WAS <EOS>', -163.64218]\n",
      "['<BOS> IN IN IN IN IN IN IN IN IN IN IN IN IN IN IN IN SHE SHE SHE SHE <EOS>', -165.07233]\n",
      "['<BOS> HAD HAD HAD HAD HAD HAD HAD HAD HAD HAD HAD HAD HAD HAD SHE SHE HIS HIS HIS HIS <EOS>', -169.05925]\n",
      "['<BOS> IN IN IN IN IN IN IN IN IN IN IN IN IN IN IN IN IN A A A <EOS>', -164.42769]\n"
     ]
    }
   ],
   "source": [
    "beam_sampler = nlp.model.BeamSearchSampler(beam_size=5,\n",
    "                                           decoder=beamDecoder(net),\n",
    "                                           eos_id=eos_id,\n",
    "                                           scorer=scorer,\n",
    "                                           max_length=20)\n",
    "\n",
    "inputs = mx.nd.array([2] * 8)\n",
    "begin_states = mx.nd.random.normal(0, 1, shape=(8, 1, 16))\n",
    "decoder_states = net.decoder.t.init_state_from_encoder(begin_states)\n",
    "generate_sequences(beam_sampler, inputs, decoder_states, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
