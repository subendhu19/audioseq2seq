{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd, gluon, autograd\n",
    "\n",
    "import gluonnlp as nlp\n",
    "import pickle\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "mx.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pickle.load(open('../data/train_processed.p', 'rb'))\n",
    "test_dataset = pickle.load(open('../data/dev_processed.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {'<pad>': [0, 1], '<unk>': [1, 1], '<BOS>': [2, 1], '<EOS>': [3, 1]}\n",
    "for item in train_dataset + test_dataset:\n",
    "    words = item[2].split(' ')\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            vocabulary[word][1] += 1\n",
    "        else:\n",
    "            vocabulary[word] = [len(vocabulary), 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    name, audio, words = x\n",
    "    split_words = ['<BOS>'] + words.split(' ') + ['<EOS>']\n",
    "    return audio, np.array([vocabulary[word][0] for word in split_words]), float(len(audio)), float(len(split_words))\n",
    "\n",
    "def get_length(x):\n",
    "    return float(len(x[1]))\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    start = time.time()\n",
    "    with mp.Pool() as pool:\n",
    "        dataset = gluon.data.SimpleDataset(pool.map(preprocess, dataset))\n",
    "        lengths = gluon.data.SimpleDataset(pool.map(get_length, dataset))\n",
    "    end = time.time()\n",
    "    print('Done! Processing Time={:.2f}s, #Samples={}'.format(end - start, len(dataset)))\n",
    "    return dataset, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Processing Time=153.64s, #Samples=28539\n",
      "Done! Processing Time=5.79s, #Samples=2703\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_data_lengths = preprocess_dataset(train_dataset)\n",
    "test_dataset, test_data_lengths = preprocess_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=28539, batch_num=894\n",
      "  key=[14, 21, 28, 35, 42, 49, 56, 63, 70, 77]\n",
      "  cnt=[1723, 1713, 2319, 5188, 8205, 6607, 2317, 420, 44, 3]\n",
      "  batch_size=[35, 32, 32, 32, 32, 32, 32, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "learning_rate, batch_size = 0.005, 32\n",
    "bucket_num, bucket_ratio = 10, 0.2\n",
    "\n",
    "def get_dataloader():\n",
    "    batchify_fn = nlp.data.batchify.Tuple(\n",
    "        nlp.data.batchify.Pad(),\n",
    "        nlp.data.batchify.Pad(),\n",
    "        nlp.data.batchify.Stack(dtype='float32'),\n",
    "        nlp.data.batchify.Stack(dtype='float32'))\n",
    "    batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
    "        train_data_lengths,\n",
    "        batch_size=batch_size,\n",
    "        num_buckets=bucket_num,\n",
    "        ratio=bucket_ratio,\n",
    "        shuffle=True)\n",
    "    print(batch_sampler.stats())\n",
    "\n",
    "    train_dataloader = gluon.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        batchify_fn=batchify_fn)\n",
    "    test_dataloader = gluon.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        batchify_fn=batchify_fn)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "train_dataloader, test_dataloader = get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "[[[ -8.37042654  -6.16026004   6.29350528 ...   0.59649253   9.17632351\n",
      "     8.05719958]\n",
      "  [ -8.51415536  -6.47229985   5.25051731 ...   3.97691196  19.89046768\n",
      "    12.82517394]\n",
      "  [ -8.86324903  -0.31330465  -1.34714977 ...  -4.47258676  19.94017961\n",
      "    11.05409373]\n",
      "  ...\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]]\n",
      "\n",
      " [[ -7.23614367 -23.17302696 -28.19189459 ...   6.40932545 -10.95141835\n",
      "     5.9777419 ]\n",
      "  [ -4.05327935 -11.33491852 -29.78987646 ...  -1.95894314  11.89255368\n",
      "    -9.4640987 ]\n",
      "  [ -3.8196864  -19.94633816 -43.70269579 ... -14.56101723   5.60094435\n",
      "    -2.42812674]\n",
      "  ...\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]]\n",
      "\n",
      " [[ -5.61902388 -21.62364674 -26.15719555 ... -10.72837888   1.15427327\n",
      "     6.96557977]\n",
      "  [ -5.57197759 -21.13965917 -26.6427496  ... -15.86990144  -0.46716087\n",
      "     8.69477938]\n",
      "  [ -5.76836347 -21.22063014 -29.53312358 ... -15.33063588  -3.01474347\n",
      "    10.39946115]\n",
      "  ...\n",
      "  [ -9.46116938 -21.2732141   14.57751808 ...   1.1300899    0.85696202\n",
      "     9.21653786]\n",
      "  [-11.44405914 -11.06755489   3.4666364  ...  -0.35756261   4.91143737\n",
      "     9.2968314 ]\n",
      "  [-11.10408987 -12.17895679   2.43333124 ... -10.8382687   -6.21133811\n",
      "    12.81698675]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -7.19297352 -18.6011587   -8.32117203 ...  -0.78849374   3.96477078\n",
      "     6.49687665]\n",
      "  [ -6.87807245 -22.0894744  -12.05022971 ...  -2.23239199   2.74722004\n",
      "     2.8836036 ]\n",
      "  [ -6.90309116 -21.80230326  -9.95968744 ...  -6.02961596   6.59062307\n",
      "     3.88266621]\n",
      "  ...\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]]\n",
      "\n",
      " [[-13.82752156 -10.65905745   5.42286346 ...   5.93815289  -1.28485525\n",
      "   -10.42641918]\n",
      "  [-13.80954798 -11.46671869   4.41431153 ...  11.5602409   -2.84628173\n",
      "   -13.6167595 ]\n",
      "  [-13.92232627 -10.57023458   4.94760082 ...   8.05282167  -8.64878199\n",
      "   -13.34025753]\n",
      "  ...\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]]\n",
      "\n",
      " [[ -8.7062517   -5.91729514   2.52400459 ...   2.93092013  -0.33556842\n",
      "     2.73252493]\n",
      "  [ -9.51790391  -1.12329003   0.76388449 ...  -3.88514398   8.91257226\n",
      "     0.43841785]\n",
      "  [ -9.71961907  -2.93688009  -0.71960261 ...  -3.55828842  13.39499205\n",
      "    -0.86318724]\n",
      "  ...\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]\n",
      "  [  0.           0.           0.         ...   0.           0.\n",
      "     0.        ]]]\n",
      "<NDArray 32x1722x13 @cpu_shared(0)>, \n",
      "[[    2   265   566 ...     0     0     0]\n",
      " [    2    34    23 ...     0     0     0]\n",
      " [    2   115    34 ...     0     0     0]\n",
      " ...\n",
      " [    2   137   600 ...   600 14517     3]\n",
      " [    2    48    30 ...    79     3     0]\n",
      " [    2   137   115 ...     3     0     0]]\n",
      "<NDArray 32x49 @cpu_shared(0)>, \n",
      "[1417. 1574. 1722. 1600. 1412. 1565. 1350. 1399. 1623. 1422. 1536. 1650.\n",
      " 1410. 1334. 1482. 1453. 1402. 1653. 1560. 1353. 1541. 1543. 1489. 1496.\n",
      " 1547. 1383. 1459. 1582. 1664. 1476. 1341. 1408.]\n",
      "<NDArray 32 @cpu_shared(0)>, \n",
      "[44. 44. 44. 46. 44. 45. 48. 45. 46. 47. 43. 48. 46. 45. 43. 46. 45. 46.\n",
      " 46. 43. 49. 45. 45. 48. 43. 45. 45. 49. 49. 49. 48. 47.]\n",
      "<NDArray 32 @cpu_shared(0)>)\n"
     ]
    }
   ],
   "source": [
    "for i, example in enumerate(train_dataloader):\n",
    "    if i >= 1:\n",
    "        break\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(Block):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.rnn = rnn.GRU(hidden_size, input_size=self.hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.swap_axes(0, 1)\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, ctx):\n",
    "        return [F.zeros((1, 1, self.hidden_size), ctx=ctx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(Block):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "            self.rnn = rnn.GRU(hidden_size, input_size=self.hidden_size)\n",
    "            self.out = nn.Dense(output_size, in_units=self.hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).swapaxes(0, 1)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, ctx):\n",
    "        return [F.zeros((1, 1, self.hidden_size), ctx=ctx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Audio2TranscriptionNet(gluon.HybridBlock):\n",
    "    def __init__(self, dropout, prefix=None, params=None):\n",
    "        super(Audio2TranscriptionNet, self).__init__(prefix=prefix, params=params)\n",
    "        with self.name_scope():\n",
    "            self.encoder = EncoderRNN(hidden_size=256)\n",
    "            self.decoder = DecoderRNN(hidden_size=256, output_size=34798)\n",
    "\n",
    "    def hybrid_forward(self, F, audio, words, audio_length, words_length): # pylint: disable=arguments-differ\n",
    "        encoded = self.encoder(audio)  \n",
    "        agg_state = self.agg_layer(encoded, valid_length)\n",
    "        out = self.output(agg_state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(hidden_size=256)\n",
    "decoder = DecoderRNN(hidden_size=256, output_size=34798)\n",
    "\n",
    "def train(net, context, epochs):\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'ftml',\n",
    "                            {'learning_rate': learning_rate})\n",
    "    loss = gluon.loss.SigmoidBCELoss()\n",
    "\n",
    "    parameters = net.collect_params().values()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        epoch_L = 0.0\n",
    "        epoch_sent_num = 0\n",
    "        epoch_wc = 0\n",
    "\n",
    "        start_log_interval_time = time.time()\n",
    "        log_interval_wc = 0\n",
    "        log_interval_sent_num = 0\n",
    "        log_interval_L = 0.0\n",
    "\n",
    "        for i, ((audio, words, alength, wlength), label) in enumerate(train_dataloader):\n",
    "            L = 0\n",
    "            wc = alength.sum().asscalar()\n",
    "            log_interval_wc += wc\n",
    "            epoch_wc += wc\n",
    "            log_interval_sent_num += audio.shape[1]\n",
    "            epoch_sent_num += audio.shape[1]\n",
    "            with autograd.record():\n",
    "                hidden = encoder.initHidden(context)\n",
    "                enc_output = encoder(audio.as_in_context(context), hidden)\n",
    "#                 L = L + loss(output, label.as_in_context(context)).mean()\n",
    "#             L.backward()\n",
    "#             # Clip gradient\n",
    "#             if grad_clip:\n",
    "#                 gluon.utils.clip_global_norm(\n",
    "#                     [p.grad(context) for p in parameters],\n",
    "#                     grad_clip)\n",
    "#             # Update parameter\n",
    "#             trainer.step(1)\n",
    "#             log_interval_L += L.asscalar()\n",
    "#             epoch_L += L.asscalar()\n",
    "#             if (i + 1) % log_interval == 0:\n",
    "#                 print(\n",
    "#                     '[Epoch {} Batch {}/{}] elapsed {:.2f} s, '\n",
    "#                     'avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
    "#                         epoch, i + 1, len(train_dataloader),\n",
    "#                         time.time() - start_log_interval_time,\n",
    "#                         log_interval_L / log_interval_sent_num, log_interval_wc\n",
    "#                         / 1000 / (time.time() - start_log_interval_time)))\n",
    "#                 # Clear log interval training stats\n",
    "#                 start_log_interval_time = time.time()\n",
    "#                 log_interval_wc = 0\n",
    "#                 log_interval_sent_num = 0\n",
    "#                 log_interval_L = 0\n",
    "#         end_epoch_time = time.time()\n",
    "#         test_avg_L, test_acc = evaluate(net, test_dataloader, context)\n",
    "#         print('[Epoch {}] train avg loss {:.6f}, test acc {:.2f}, '\n",
    "#               'test avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
    "#                   epoch, epoch_L / epoch_sent_num, test_acc, test_avg_L,\n",
    "#                   epoch_wc / 1000 / (end_epoch_time - start_epoch_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
